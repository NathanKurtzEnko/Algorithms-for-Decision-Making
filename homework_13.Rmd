---
title: "homework 13"
author: "Nathan Kurtz-Enko"
date: "4/2/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(FNN)
library(dplyr)
library(ggplot2)
library(tree)
```

## 2 Assignment
Consider the dataset in Prostate.csv (tab separated) with lpsa as the response variable.  The dataset contains a field indicating train/test. Separate out the data.df (a training set) and validate.df (a testing set).



```{r}
prostate.df <- read.csv("~/ADM/Prostate.csv",row.names = 1, sep = "\t")
#with(prostate.df,table(train))
#names(prostate.df)
data.df<-prostate.df %>% 
  filter(train)
validate.df<-prostate.df %>% 
  filter(!train)


```

* Part 1: Build a maximal tree on data.df and then use cv.tree  to get an estimate of the optimial tree size.

```{r}
max_tree<-tree(lpsa ~ ., data=data.df,
             control=tree.control(nrow(data.df),minsize=1))

## Number of terminal leaves...look at max.tree$frame$var. The terminal leaves have
## have the value var
opt_size <- sum(max_tree$frame$var=="<leaf>")

print(str_c("The optimal size for maximal tree is ", opt_size))
```

* Part 2: Use the train/test data set to manually search for the optimal tree size. Prune the tree back one leaf at the time and estimate the mse errors for both train and test. Note: use minsize=1 to get a (close to) maximal tree.


```{r, warning=FALSE}

preds <- predict(max_tree, newdata = validate.df)
numLeaves <- 2:20
stuff <- tibble(leaves = numLeaves, mse_train = numLeaves, mse_test = numLeaves)
for(l in numLeaves){
  pruned_tree <- prune.tree(max_tree,best=l) 
  train_preds <- predict(pruned_tree, newdata = data.df)
  test_preds <- predict(pruned_tree, newdata = validate.df)
  err_train <- mean((train_preds-data.df$lpsa)^2)
  err_val <- mean((test_preds-validate.df$lpsa)^2)
  stuff[l-1, 2] = err_train
  stuff[l-1, 3] = err_val
}

#mean((preds - validate.df$lpsa)^2)
```

```{r}
min_mse_train <- min(stuff$mse_train)
min_mse_test <- min(stuff$mse_test)

min_train <- stuff %>%
  filter(mse_train == min_mse_train)
leaves_train <- (min_train$leaves)[1]

min_test <- stuff %>%
  filter(mse_test == min_mse_test)
leaves_test <- (min_test$leaves)[1]

#min_mse_test
#min_mse_train

#leaves_train
#leaves_test
print(str_c("The number of leaves that resulted in minimum train error, ", min_mse_train, ", is ", leaves_train))
print(str_c("The number of leaves that resulted in minimum test error, ", min_mse_test, ", is ", leaves_test))
```



* Part 3: Use the prune.tree function to "prune" the tree to smaller sizes (determined by the number of terminal leaves. For each smaller tree size, use cross-validation on data.df to estimate the mse error.  Also, for each tree size,  calculate the training error (using data.df) and the validation error (using validate.df).
Use these to construct an analog of Figure 8.5 (error bars are optional).
 Do you see  similar shapes of the graphs?cars)


```{r}
tree_cv <- function(df, prune) {
  kfolds <- 10
  folds <-sample(1:kfolds,ncol(df),rep=T)
  mseCV <- numeric(kfolds)
  for(f in 1:kfolds){
    train <- df[folds != f,]
    test <- df[folds == f,]
    tree_model <- tree(lpsa ~ ., data = train, control = tree.control(nrow(train), minsize = 1))
    pruned_tree <- prune.tree(tree_model, best = prune)
    pred <- predict(pruned_tree, newdata = test)
    mseCV[f] <- mean((pred-test$lpsa)^2, na.rm = TRUE)
  }
  mean(mseCV, na.rm = TRUE)
  
}
```

```{r, warning=FALSE}
#prune at a bunch of different amounts, for each amount use crossvalidation to find mse, find mse when just using training data, and find mse when using testing data

number_leaves <- 2:20
mses_and_stuff <- tibble(leaves = number_leaves, cv_err = number_leaves,
                         train_err = number_leaves, test_err = number_leaves)

for(l in number_leaves){
  cv_err <- tree_cv(data.df, l)
  pruned_tree_model <- prune.tree(max_tree, best = l)
  train_preds <- predict(pruned_tree_model, newdata = data.df)
  test_preds <- predict(pruned_tree_model, newdata = validate.df)
  train_err <- mean((train_preds - data.df$lpsa)^2)
  test_err <- mean((test_preds - validate.df$lpsa)^2)
  mses_and_stuff[l-1, 2] = cv_err
  mses_and_stuff[l-1, 3] = train_err
  mses_and_stuff[l-1, 4] = test_err

}
```

```{r}
ggplot(mses_and_stuff)+
  geom_point(aes(x = leaves, y = cv_err), color = "blue")+
  geom_line(aes(x = leaves, y = cv_err), color = "blue")+
  geom_point(aes(x = leaves, y = train_err), color = "orange")+
  geom_line(aes(x = leaves, y = train_err), color = "orange")+
  geom_point(aes(x = leaves, y = test_err), color = "green")+
  geom_line(aes(x = leaves, y = test_err), color = "green")+
  ggtitle("CV Error (blue) vs Training Error (orange) vs Test Error (green)")+
  xlab("Leaves")+
  ylab("Error")
```