---
title: "homework_7"
author: "Nathan Kurtz-Enko"
date: "3/5/2019"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

## Assignment
Use train+test data with these three  logistic regression models

* One Predictor: balance
* Two Predictors: balance and income
* Three Predictors: balance, income, and student

In each case, create a logistic regression model (as above). Determine the best threshold value by computing training error rates over a sequence of threshold values. For each value, use a train+test combination to determine your estimate of the error rate. Report the best threshold value and the best error rate. 


```{r,message=FALSE, include=FALSE}
library(ggplot2)
library(tidyverse)
library(ISLR)
library(dplyr)
```

```{r}
#Here we will be using the default dataset from ISLR package
names(Default)
str(Default)
nrow(Default)

Default <- Default %>%
  mutate(default_val = ifelse(default == "Yes", 1, 0),
         student_val = ifelse(student == "Yes", 1, 0))
```

```{r}
#create our training and testing data
(n<-nrow(Default))
train<-sample(1:n,n/2,rep=F)
train.df<-Default[train,]
test.df<-Default[-train,]
```

#one predictor: balance

```{r}
#testing one predictor
mod.log <- glm(default_val~balance,
               family=binomial,
               data=train.df)
probs <- predict(mod.log, newdata = test.df, type = "response")

test2.df <- test.df %>%
  mutate(probs_default = probs)
```

```{r}
#see how this looks
ggplot(test2.df)+
  geom_jitter(aes(x = balance, y = default_val), color = "blue")+
  geom_point(aes(x = balance, y = probs_default), color = "red")
```

```{r}
#find the best threshold
#define a functions to calculate error
calcErr <- function(threshold) {
 test2.df <- test2.df %>% 
  mutate(pred_default = ifelse(probs_default < threshold,0,1))
  with(test2.df, mean(default_val != pred_default))
}

#define a range of thresholds
thresh_rng <- seq(from = 0, to = .5, length.out = 100)

#thresh_err <- tibble(thresh = thresh_rng, err = thresh_rng)
#calculate errors for thresholds
errs <- map_dbl(thresh_rng, calcErr)

plot(thresh_rng, errs)

min_err <- min(errs)

index <- match(min_err, errs)

best_thresh <- thresh_rng[index]

test3.df <- test2.df %>%
  mutate(pred_default = ifelse(probs_default < best_thresh, 0, 1)) #0 means no and 1 means yes

ggplot(test3.df)+
  geom_jitter(aes(x = balance, y = default_val), color = 'blue', alpha = .3)+
  geom_jitter(aes(x = balance, y = pred_default), color = "red", alpha = .3)+
  ggtitle("Default by balance: red = default prediction, blue = actual default")

error_rate <- mean(test3.df$pred_default != test3.df$default_val)
paste0(str_c("error_rate: ", error_rate))
paste0(str_c("best threshold: ", best_thresh))
```

#now with two predictors

```{r}

calcErr <- function(threshold) {
 test4.df <- test4.df %>% 
  mutate(pred_default = ifelse(probs_default < threshold,0,1))
  with(test4.df, mean(default_val != pred_default))
}

mod.log <- glm(default_val~balance+income,
               family=binomial,
               data=train.df)
probs <- predict(mod.log, newdata = test.df, type = "response")

test4.df <- test.df %>%
  mutate(probs_default = probs)

errs <- map_dbl(thresh_rng, calcErr)

plot(thresh_rng, errs)

min_err <- min(errs)

index <- match(min_err, errs)

best_thresh2 <- thresh_rng[index]

test5.df <- test4.df %>%
  mutate(pred_default = ifelse(probs_default < best_thresh2, 0, 1)) #0 means no and 1 means yes

ggplot(test5.df)+
  geom_jitter(aes(x = balance, y = income, color = factor(default)), alpha = .3)+
  ggtitle("Actual default by balance and income")

ggplot(test5.df)+
  geom_jitter(aes(x = balance, y = income, color = factor(pred_default)), alpha = .3)+
  ggtitle("predicted default by balance and income")

error_rate2 <- mean(test5.df$pred_default != test5.df$default_val)
paste0(str_c("error_rate: ", error_rate2))
paste0(str_c("best threshold: ", best_thresh2))
```

#now three predictors

```{r}
calcErr <- function(threshold) {
 test6.df <- test6.df %>% 
  mutate(pred_default = ifelse(probs_default < threshold,0,1))
  with(test6.df, mean(default_val != pred_default))
}

mod.log <- glm(default_val~balance+income+student,
               family=binomial,
               data=train.df)
probs <- predict(mod.log, newdata = test.df, type = "response")

test6.df <- test.df %>%
  mutate(probs_default = probs)

errs <- map_dbl(thresh_rng, calcErr)

plot(thresh_rng, errs)

min_err <- min(errs)

index <- match(min_err, errs)

best_thresh3 <- thresh_rng[index]

test7.df <- test6.df %>%
  mutate(pred_default = ifelse(probs_default < best_thresh3, 0, 1)) #0 means no and 1 means yes

ggplot(test7.df)+
  geom_jitter(aes(x = balance, y = income, color = factor(default), shape = student), alpha = .4)+
  ggtitle("Actual default by balance and income")

ggplot(test7.df)+
  geom_jitter(aes(x = balance, y = income, color = factor(pred_default), shape = student), alpha = .4)+
  ggtitle("predicted default by balance and income")

error_rate3 <- mean(test7.df$pred_default != test7.df$default_val)
paste0(str_c("error_rate: ", error_rate3))
paste0(str_c("best threshold: ", best_thresh3))
```

#overview

```{r}
overview <- tibble(num_predictors = 1:3, 
                   best_thresh = c(best_thresh, best_thresh2, best_thresh3),
                   error_rate = c(error_rate, error_rate2, error_rate3))

overview
```




# Assignment  

Your task is to create a model to predict "success" of a candidates based on performance metrics You have two data sets:

* trainPerformance.csv
* testPerformance.csv

In each data set, there are 11 fields. The first 10 are performance metrics, the last one is a boolean (True/False) field indicating if the candidate was a "star" the after being hired. 

The two sets have identical structures. The plan is to build your model on the training data, and evaluate it (test it) on the the test data. Your work is scored by a cost matrix
## Cost Matrix
* **Predict** **Actual** **Cost**
* FALSE    FALSE     0    (no risk/no reward)
* NO       TRUE      20   (oops, undervalued a candidate)
* TRUE     FALSE     50   (bigger oops, overvalued a candidate)
* TRUE     TRUE     -10  (a reward! you picked a winner)


Build a logistic regression model with up to five predictors number (no interactions)  to predict next year's performance outcome status. Find an optimal a probability threshhold that will maximize the total reward.

Also, if you want to, build a KNN model to for the same task. With KNN, you will have to optimize on both the threshold and the the value of k (nearest neighbors).

```{r, include=FALSE}
library(GGally)

```

```{r}
train <- read_csv("~/ADM/class/trainPerformance.csv")
test <- read_csv("~/ADM/class/testPerformance.csv")
ggpairs(train)
```

```{r}
model <- glm(resp~pred1+pred3+pred5+pred6+pred9, 
             family = binomial,
             data = train)

probs <- predict(model, newdata = test, type = "response")

calcErr <- function(threshold) {
 test <- test %>% 
  mutate(pred = ifelse(probs < threshold, FALSE, TRUE))
  with(test, mean(resp != pred))
}

errors <- map_dbl(thresh_rng, calcErr)

min_error_index <- match(min(errors), errors)

best_thresh4 <- thresh_rng[min_error_index]

test2 <- test %>%
  mutate(pred = ifelse(probs < best_thresh4, FALSE, TRUE))


paste0(str_c("error rate: ", min(errors)))
```

```{r}
ggplot(test2)+
  geom_bar(aes(x = resp, fill = pred))
```

