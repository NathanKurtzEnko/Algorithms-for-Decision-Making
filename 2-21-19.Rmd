---
title: "2-21-19.Rmd"
author: "Nathan Kurtz-Enko"
date: "2/23/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(class) ##for knn function
library(dplyr)
```

## Introduction
Let's look at a simple prediction scenario using KNN models. To get started, we'll look at the well-trod *iris* dataset, included in the R distribution.

```{r}
summary(iris)
```

This data set contains four fields with measurements of sepals and petals or three types of irises. 

```{r}
names(iris)
```

A good starting point is to look at some plots. 
How about Sepal.Length+Petal.Length
```{r}
iris %>% 
  ggplot()+
  geom_point(aes(Sepal.Length,Petal.Length,color=Species))
```
Or...Sepal.Width+Petal.Width?
```{r}
iris %>% 
  ggplot()+
  geom_point(aes(Sepal.Width,Petal.Width,color=Species))
```
It appears as if the Species separate very nicely. This is one reason the data set has lived on for so long. It's a bit too nice for any serious analysis, but it is a good place to get started on the process.

## Scaling
The first four fields are the predictors. They are on somewhat different scales so we need to **scale** the data.

Here's how....just apply *scale* to all but the last field.
```{r}
iris0<-scale(iris[,-5])
iris.df<-data.frame(iris0,Species=iris$Species)
```
You can check that the scaling works...look at, for example, the Petal values.
```{r}
with(iris.df,c(mean(Petal.Width),var(Petal.Width)))
with(iris, c(mean(Petal.Width), var(Petal.Width)))
```
As desired.

KNN will do multi-class (Number of classes > 2) classification, but let's reduce to binary classification.


Create a catagorical variable for being Sertosa (or not).
```{r}
iris1.df<-iris.df %>% 
  mutate(isSetosa= (Species=="setosa")) %>% 
  select(-Species)
```

# Train and test data
In the the case of real data (vs. synthetic data) we can't just generate more data whenever we want it. We need to use the data we have.

One way to create train/test data is to simply split the data (more or less) in half. 

Do this randomly!

Here's my favorite incantation. Create a sample of of half the index set. 
```{r}
num<-nrow(iris.df)
train<-sample(1:num,num/2,rep=F)
train.df<-iris1.df[train,]
test.df<-iris1.df[-train,]
```

## KNN Time
Here we go.

First we  need to be careful extracting data in the correct form

```{r}
train.dat<-train.df[,1:4]
classes<-with(train.df,isSetosa)
test.dat<-test.df[,1:4]
```
Here we go...suppose we want to use 5 nearest neighbors.
```{r}
kval<-5
knn.mod<-knn(train.dat,test.dat,classes,kval)
```
How did it turn out?

```{r}
with(test.df,table(isSetosa,knn.mod))
(err<-with(test.df,mean(isSetosa!=knn.mod)))
```
Wow, that's some serious classification success.

But did we get lucky? To test, we can repeat the process above a number of times and keep track of the results.


```{r}
numReps<-25
errs<-numeric(numReps)
```


```{r}
for(m in numReps){
  train<-sample(1:num,num/2,rep=F)
  train.df<-iris1.df[train,]
  test.df<-iris1.df[-train,]
  knn.mod<-knn(train.dat,test.dat,classes,5)
  errs[m]<-with(test.df,mean(isSetosa!=knn.mod))
}
mean(errs)
```
Looks like this classification works pretty good (too good).


## Best k
To find the best value of k (not hard here!)
For each value of k, repeat with different train/test data sets
 to smooth things out. Look at the the value of k which minimizes the error rate. 
 
 
#Haberman's Survival Data Set
Take a look at the description of the data set found at the UIC Machine Learning Repository.

https://archive.ics.uci.edu/ml/datasets/Haberman%27s+Survival


## Null Rate
In many cases, especially when the outcomes are weighted heavily toward one of the classes, the so-called *Null Rate* is relevant. The null rate is simple the error rate of the "most likely classification", namely the classification of everything as the most common class. (Almost everyone likes pizza best, so I am going to guess that everyone likes pizza best.)

Calculate the null rate for this data set. If you can't beat the null rate, your classification algorithm isn't very useful.

Note: The null rate  plays a role similar to the Bayesfk Error Rate.

```{r}
#null rate is assuming everything is the most common class, then find the error of this assumption
is <- iris1.df%>%
  filter(isSetosa==TRUE)%>%
  count()
is_not <- iris1.df %>%
  filter(isSetosa==FALSE)%>%
  count()

is>is_not
null_rate <- is/(is+is_not)
null_rate
```


## Your assignment
Use KNN to build a classifier which will predict the outcome variable (5-year survival) based on this data set. Can you do better than the null rate?

Produce a single, self-contained, nicely documented RMarkdown file with your analysis and conclusion (about the efficacy of your prediction algorithm). 

Note:

  * Make sure you scale your data
  * Call your dataset haberman.csv. Include variables indicating the location
  of the data. This way the graders (and me) can easily modify your RMarkdown   to load the data.
* To calculate the error rate for a particular value of k, you must do multiple repetitions of the train/test process. A large number of repetitions will give a more solid estimate of the error rate. 
* Visualizations are required. 