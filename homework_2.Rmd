---
title: "homework 2"
author: "Nathan Kurtz-Enko"
output: pdf_document
---

#Assignment
Redo this process with different underlying data models. In other
words, alter how the model above was defined to generate the
data. In the example above, I used two normal distributions, two
for each of the classes. They had different means, but the same
variances. Also, both classes had the same number of data points.

Possible modifications include replacing the normal distribution
with, say, the uniform.
```{r, include=FALSE}
library(tidyverse)
```

```{r}
###build data

#define means
c1 <- c(-1,0)
c2 <- c(-2,1)

#define standard deviations
s1 <- .7 
s2 <- .7

#define numbers of data points
m1 <- 100
m2 <- 100

#define classes
class <- c("A", "B")

#define vectors of randomly generated normal distribution data points
v1 <- rnorm(m1, c1[1], s1)
v2 <- rnorm(m1, c1[2], s1)
v3 <- rnorm(m2, c2[1], s2)
v4 <- rnorm(m2, c2[2], s2)

#sample vectors
x1 <- sample(c(v1,v2), m1, rep=F)
x2 <- sample(c(v3,v4), m2, rep=F)
```

```{r}
#create tibble or data frame
training_data <- tibble(value = c(x1,x2), class = factor(c(rep("A", m1), rep("B", m2))))
```

```{r}
#make plot
x_values <- seq(-4,4,.01)
a_class <- training_data %>%
  filter(class == "A")
b_class <- training_data %>%
  filter(class == "B")
ggplot()+
  geom_line(aes(x = x_values, y = dnorm(x_values, c1[1], s1)), color = "red")+
  geom_line(aes(x = x_values, y = dnorm(x_values, c1[2], s1)), color = "red")+
  geom_line(aes(x = x_values, y = dnorm(x_values, c2[1], s2)), color = "blue")+
  geom_line(aes(x = x_values, y = dnorm(x_values, c2[2], s2)), color = "blue")+
  geom_point(data = a_class, aes(x = value, y = 0), color = "red")+
  geom_point(data = b_class, aes(x = value, y = -.2), color = "blue")+
  ggtitle("Distribution", subtitle = "class a = red, class b = blue")
```

```{r}
###determine optimal value of K

#best error
bayes_probability_class_a<-function(x){
  ##Prob (unnormalized) of being in class A
  p1<-sum(dnorm(x,c1,s1))
  ##Prob (unnormalized) of being in class B
  p2<-sum(dnorm(x,c2,s2))
  p1/(p1+p2)
}
```

```{r}
probability_class_a <- map_dbl(training_data$value, bayes_probability_class_a)

training_data_error_calc <- training_data %>%
  mutate(bayes_prediction_class_a = probability_class_a > .5,
         bayes_prediction_class = ifelse(bayes_prediction_class_a, "A", "B"))

bayes_error <- mean(!(training_data_error_calc$class)==(training_data_error_calc$bayes_prediction_class))
```

```{r}
#plot
bayes_class_a <- training_data_error_calc %>%
  filter(bayes_prediction_class == "A")
bayes_class_b <- training_data_error_calc %>%
  filter(bayes_prediction_class == "B")
ggplot()+
  geom_line(aes(x = x_values, y = dnorm(x_values, c1[1], s1)), color = "red")+
  geom_line(aes(x = x_values, y = dnorm(x_values, c1[2], s1)), color = "red")+
  geom_line(aes(x = x_values, y = dnorm(x_values, c2[1], s2)), color = "blue")+
  geom_line(aes(x = x_values, y = dnorm(x_values, c2[2], s2)), color = "blue")+
  geom_point(data = a_class, aes(x = value, y = 0), color = "red")+
  geom_point(data = b_class, aes(x = value, y = -.2), color = "blue")+
  ggtitle("Distribution", subtitle = "class a = red, class b = blue")+
  geom_point(data = bayes_class_a, aes(x = value, y = -.4), color = "red")+
  geom_point(data = bayes_class_b, aes(x = value, y = -.6), color = "blue")

```

```{r}
#define range of values for K
k <- 1:20

#define test point
x0 <- .2

#define distance function
distance <- function(x_i, x_f){
  abs(x_f-x_i)
}
```

```{r}
#find and sort distances of all data points from test point
training_data3 <- training_data_error_calc %>%
  mutate( `dist from x0` = map_dbl(training_data_error_calc$value, function(x) distance(x0, x)),
          id = 1:n())%>%
    arrange(`dist from x0`)

#knn values
knn_vals <- training_data3 %>%
  slice(k)
```

```{r}
#plot
ggplot(data = training_data3)+
  geom_point(aes(x = id, y = value, color=id %in% knn_vals$id))+
  guides(color=F)+
  geom_hline(yintercept=x0,color="orange",size=1)
```

```{r}

#made prediction
myKnn<-function(pt,kval,train_data,allResp=FALSE){
  ##make sure kNear isn't too big
  kval<-min(nrow(train_data),kval)
  ##identify the classes
  classes<- with(train_data, as.character(unique(class)))
  xVals<-with(train_data,value)
  tot<-length(xVals)
  ##get the ascending order of distances
  allOrds<-order(map_dbl(xVals,function(x) distance(x, pt)))
  ##get the k closest
  closest<-allOrds[1:kval]
  ##Decide which class wins..not the most elegant ending.
  ## But I haven't seen an easier way 
  ##extract the classes of the the closest
  ##Take the mean equal to classes[1]
  p<-with(train_data[closest,],mean(class==classes[1]))
  if(p>0.5){
    res<-classes[1]
  }else{
    res<-classes[2]
  }
  ##Check how much output to return
  if(allResp){
    ## a list of resp, probability, and the indices of the nhbs.
    list(res,p,(1:tot)[closest])
  } else{
    res
  }
}

#extend prediction function to work over all data
myKnn2 <- function(test_data,kval,train_data){
   with(test_data,
      ##send each x value in the data frame 
      ## to myKnn.
      ##map over the x values in test.df. 
      ##map_chr because the returns are "A"/"B"
     map_chr(value,
             function(x1) myKnn(x1,kval,train_data)))
}
```

```{r}
#check performance
k1 <- 5

knn_pred1 <- myKnn2(training_data3, k1, training_data3)
training_data_pred <- training_data3 %>%
  mutate(knn_prediction = knn_pred1)
  
knn_class_a <- training_data_pred %>%
  filter(knn_prediction == "A")
knn_class_b <- training_data_pred %>%
  filter(knn_prediction == "B")
ggplot()+
  geom_line(aes(x = x_values, y = dnorm(x_values, c1[1], s1)), color = "red")+
  geom_line(aes(x = x_values, y = dnorm(x_values, c1[2], s1)), color = "red")+
  geom_line(aes(x = x_values, y = dnorm(x_values, c2[1], s2)), color = "blue")+
  geom_line(aes(x = x_values, y = dnorm(x_values, c2[2], s2)), color = "blue")+
  geom_point(data = a_class, aes(x = value, y = 0), color = "red")+
  geom_point(data = b_class, aes(x = value, y = -.2), color = "blue")+
  ggtitle("Distribution", subtitle = "class a = red, class b = blue")+
  geom_point(data = bayes_class_a, aes(x = value, y = -.4), color = "red")+
  geom_point(data = bayes_class_b, aes(x = value, y = -.6), color = "blue")+
  geom_point(data = knn_class_a, aes(x = value, y = -.8), color = "red")+
  geom_point(data = knn_class_b, aes(x = value, y = -1), color = "blue")  
```

