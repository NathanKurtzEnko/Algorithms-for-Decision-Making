---
title: "3-12-19"
author: "Nathan Kurtz-Enko"
date: "3/12/2019"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library(tidyverse)
library(MASS)

# Data Generation
##orange
oVals<-matrix(c(3,3*pi/9,2,5*pi/9,1,7*pi/9),byrow=T,nrow=3)
omu<- c(cos(oVals[,2]),sin(oVals[,2]))
oMus<-oVals[,1]*matrix(omu,byrow=F,nrow=3)

##blue
bVals<-matrix(c(3,9*pi/9,2,11*pi/9,1,13*pi/9),byrow=T,nrow=3)
bmu<-c(cos(bVals[,2]),sin(bVals[,2]))
bMus<-bVals[1,]*matrix(bmu,byrow=F,nrow=3)

##purple
pVals<-matrix(c(3,15*pi/9,2,17*pi/9,1,1*pi/9),byrow=T,nrow=3)
pmu<-c(cos(pVals[,2]),sin(pVals[,2]))
pMus<-pVals[1,1]*matrix(pmu,byrow=F,nrow=3)
cols<-c("orange","blue","purple")
sig<-diag(c(1,1))

##unequal variances
oSig<-diag(c(1,1))
bSig<-diag(c(1,2))
pSig<-diag(c(1,2))

############
## Pick a location of datum in a color class (datum is like a plural for data)
doPick<-function(pickCol){
  pick<-sample(1:3,1)
  if(pickCol==1){
    mu=oMus[pick,]
    sig<-oSig
  }
  if(pickCol==2){
    mu=bMus[pick,]
    sig<-bSig
  }
  if(pickCol==3){
    mu=pMus[pick,]
    sig<-pSig
  }
  mvrnorm(1,mu,sig)
}

doPick(1)

N<-1000
dat<-matrix(ncol=3,nrow=N)
numClass<-2 #you can set this to three if you want three classes
for(n in 1:N){
  ## random classes
  pickCol<-sample(1:numClass,1)
  ## Equal size classes
  ## pickCol<- 1+(n %%2)
  ##compute it
  dat[n,]<-c(doPick(pickCol),pickCol)
}



data.df<-data.frame(dat)
names(data.df)<-c("x","y","class")

with(data.df,table(class))

data.df<-data.df %>% 
  mutate(class=as.factor(class))

gg1<-data.df %>% 
  ggplot()+
  geom_point(aes(x,y,color=class))+
  scale_color_manual(values=cols)+
  coord_fixed()
gg1

```

```{r}
## #######################
## Non linear
  
## #######################
## Build a nonlinear component

data.df <- data.df %>%
  mutate(y2=y^2/5)

gg2<-data.df %>% 
  ggplot()+
  geom_point(aes(x,y2,color=class))+
  scale_color_manual(values=cols)+
  coord_fixed()
gg2

```

```{r}
###############
## Build a lda model
mod.lda<-lda(class~x+y,data=data.df)
pred.lda<-predict(mod.lda,newdata=data.df)
with(data.df,table(class,pred.lda$class))

```

```{r}
## Grid it
xrange<-range(data.df$x)
xvals<-seq(xrange[1],xrange[2],by=.1)
yrange<-range(data.df$y)
yvals<-seq(yrange[1],yrange[2],by=.1)
grid.xy<-expand.grid(xvals,yvals)
grid.df<-data.frame(x=grid.xy[,1],
                    y=grid.xy[,2])

```

```{r}
##Make grid predictions
grid.pred<-predict(mod.lda,newdata = grid.df)
grid.df$class.pred<-grid.pred$class

```

```{r}
#######
## What does it look like?
gg2<-gg1+
  geom_tile(data=grid.df,aes(x,y,fill=class.pred),alpha=.1)+
  scale_fill_manual(values= cols)+
  guides(fill=F)
gg2

```

```{r}
## #######################
## Extract the scaling
scaling<-mod.lda$scaling
##normalize to unit length
scaling<-scaling/sqrt(sum(scaling^2))

gg2+
  geom_abline(intercept=0,slope=scaling[2]/scaling[2])
```

```{r}
## #######################
## What is this telling us?
## Project the data onto the scaling vector
dim(scaling)
(data.df$val<-as.numeric(dat[,1:2]%*%scaling))
```

```{r}
##What do we have?
## compute the mean and variance by class
sum.df<-data.df %>% 
  group_by(class) %>% 
  summarize(mu=mean(val),
            sd2=var(val),
            size=n())
sum.df

```

```{r}
## #######################
## The goal is to maximize the
## bewteen group differences (difference of group means)
## and the within group difference (group variances)

##Bewtween group
mu<-sum.df["mu"]
s2<-sum.df["sd2"]
classSize<-sum.df["size"]
S_between<-abs(sum(mu*c(1,-1)))^2
S_within<-sum(s2*(classSize-1))/(N-numClass)
```

```{r}
##And here it is...
S_between/S_within
```

```{r}

## #######################
## Compared to what?
## What about projecting in other directions

##Here's an arbitrary direction
vec<-c(0,1)
vec<-vec/sqrt(sum(vec^2))
```

```{r}
##repeat everything above
data.df$val<-as.numeric(dat[,1:2]%*%vec)
sum.df<-data.df %>% 
  group_by(class) %>% 
  summarize(mu=mean(val),
            sd2=var(val),
            size=n())
```

```{r}
##same as above
mu<-sum.df["mu"]
s2<-sum.df["sd2"]
classSize<-sum.df["size"]
S_between<-abs(sum(mu*c(1,-1)))^2
S_within<-sum(s2*(classSize-1))/(N-numClass)
##And here it is...
S_between/S_within
```

```{r}
## #######################
## Build a function to compute this quantity
##
calcRat<-function(vec){
  data.df$val<-as.numeric(dat[,1:2]%*%vec)
  ##  
  sum.df<-data.df %>% 
    group_by(class) %>% 
    summarize(mu=mean(val),
              sd2=var(val),
              size=n())
  ## 
  S_between<-abs(sum(sum.df["mu"]*c(1,-1)))^2
  ## Equal class size
  ## S_within<-sum(sum.df["sd2"])
  ## unequal
  classSize<-sum.df["size"]
  S_within<-sum(sum.df["sd2"]*(classSize-1))/(N-numClass)
  S_between/S_within
}
```

```{r}
##Checking
calcRat(vec)
## versus
calcRat(scaling)
```

```{r}

## #######################
## Construct a plot of this quantity as a function of angle theta between
## 0 and pi

## Here we go...
K<-500
thetas<-seq(0,pi,len=K)
ratVals<-map_dbl(thetas,function(theta) calcRat(c(cos(theta),sin(theta))))
```

```{r}
## The plot..
data.frame(theta=thetas,ratio=ratVals) %>% 
  ggplot()+
  geom_point(aes(theta,ratio),size=.3)
```

```{r}
##You can see the max...let's track it down
max(ratVals)
calcRat(scaling)
id<-which.max(ratVals)
(theta<-thetas[id])
## here's the vector that produces the max
c(cos(theta),sin(theta))
## same as (up to sign), up to precision
scaling


```

```{r}
## #######################
## Consider  K=3 classes
N<-100
dat<-matrix(ncol=3,nrow=N)
numClass<-3
for(n in 1:N){
  ## random classes
  pickCol<-sample(1:numClass,1)
  ## Equal size classes
  ## pickCol<- 1+(n %%2)
  ##compute it
  dat[n,]<-c(doPick(pickCol),pickCol)
}
```

```{r}
## #######################
## Redo the calculations above with K=3 classes




## #######################
## Or even more predictors
## Different data generation scheme.
K<-3
p<-5
mu1<-c(1,0,0,0,0)
mu2<-c(0,1,0,0,0)
mu3<-c(0,0,1,0,0)
mu4<-c(0,0,0,1,0)
mu5<-c(0,0,0,0,1)
mu<-matrix(c(mu1,mu2,mu3,mu4,mu5),nrow=p)
sig<-diag(c(1,1,1,1,1))

N<-300

classes<-sample(1:K,N,rep=T)


dat<-matrix(nrow=N,ncol=p)
for(n in 1:N){
  dat[n,]<-mvrnorm(1,mu[,classes[n]],sig)
}

data.df<-data.frame(dat,class=factor(classes))
names(data.df)[1:p]<-paste0("x",1:p)
str(data.df)
```

```{r}
## #######################
## look at a pair of predictors
data.df %>%
  ggplot()+
  geom_point(aes(x1,x2,color=class))
```

```{r}
## #######################
## other pair
data.df %>%
  ggplot()+
  geom_point(aes(x1,x5,color=class))
```

```{r}
## #######################
## It's hard to get a good look at the data
## LDA is an efficient tool for dimension reduction
## In this case, we can go from 5 dim space to 2 dim space


## #######################
## run lda
mod.lda<-lda(class~.,data=data.df)


## Do the Scaling
## There are 2=K-1 scaling directions
scaling<-mod.lda$scaling
s1<-scaling[,1]
s2<-scaling[,2]
##normalize
s1<-s1/sqrt(sum(s1^2))
s2<-s2/sqrt(sum(s2^2))
```

```{r}
## #######################
## transform to the scaling direction
u1 <- dat %*% s1
u2 <- dat %*% s2
data.df$u1 <- u1[,1]
data.df$u2 <- u2[,1]
```

```{r}

## #######################
## Now we can view the data in a space with
## K-1=2  predictors

data.df %>%
  ggplot()+
  geom_point(aes(u1,u2,color=class))

```

```{r}
## #######################
## Add Prediction Grid for decision boundaries
mod.lda2<-lda(class~ u1+u2,
              data=data.df)
```

```{r}
## #######################
## Build a grid, as before
rang1<-range(data.df$u1)
rang2<-range(data.df$u2)
val1<-seq(rang1[1],rang1[2],by=.1)
val2<-seq(rang2[1],rang2[2],by=.1)
grid.xy<-expand.grid(val1,val2)
grid.df<-data.frame(u1=grid.xy[,1],
                    u2=grid.xy[,2])

```

```{r}
## Predictions on the grid
preds<-predict(mod.lda2,newdata=grid.df)                    
grid.df$pred.grid <- preds$class
  

## #######################
## Plot the grid values to see decision regions
## in the reduced dimension space
grid.df %>%
  ggplot()+
  geom_point(data=data.df,aes(u1,u2,color=class))+
  geom_tile(aes(u1,u2,fill=pred.grid),alpha=.3)+
  guides(fill=F)+
  ggtitle("Data in LDA Projection Space, with decision bndry")


## Measure error rate on training data, what the heck
pred<-predict(mod.lda2,newdata=data.df)

with(data.df,table(class,pred$class))
with(data.df,mean(class != pred$class))
```

